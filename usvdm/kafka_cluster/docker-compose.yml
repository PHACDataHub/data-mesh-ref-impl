version: "3.8"

##############################################################################
#
# services
#
# - Uses .env for environment variables
# - Kafka Cluster, Community Edition, Starter version (see below for details)
#
##############################################################################

services:

##############################################################################
#
# Kafka Cluster, Community Edition, Starter version
# -------------------------------------------------
# - zookeeper
# - broker
# - schema-registry
# - connect
# - kafka-ui
#
##############################################################################

  ####################
  # zookeeper
  ####################
  zookeeper:
    image: confluentinc/cp-zookeeper:${KAFKA_VERSION}
    hostname: zookeeper
    container_name: zookeeper
    networks:
      - backend
    ports:
      - ${ZOOKEEPER_CLIENT_PORT}:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_CLIENT_PORT}
      ZOOKEEPER_TICK_TIME: ${ZOOKEEPER_TICK_TIME}
      ZOOKEEPER_LOG4J_ROOT_LOGLEVEL: WARN
      ZOOKEEPER_TOOLS_LOG4J_LOGLEVEL: ERROR
    volumes:
      - $PWD/kafka-ce/zk/data:/var/lib/zookeeper/data
      - $PWD/kafka-ce/zk/txn-logs:/var/lib/zookeeper/log
    restart: always

  ####################
  # broker
  ####################
  broker:
    image: confluentinc/cp-kafka:${KAFKA_VERSION}
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    networks:
      - backend
    ports:
      - ${BROKER_EXTERNAL_PORT}:${BROKER_EXTERNAL_PORT}
      - ${BROKER_LOCAL_PORT}:${BROKER_LOCAL_PORT}
      - ${BROKER_JMX_PORT}:9101
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:${ZOOKEEPER_CLIENT_PORT}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:${BROKER_INTERNAL_PORT},PLAINTEXT_HOST://localhost:${BROKER_LOCAL_PORT}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 10000
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: ${REPLICATION_FACTOR}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      KAFKA_DELETE_TOPIC_ENABLE: true
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: broker
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:${SCHEMA_REGISTRY_PORT}
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
      KAFKA_TOOLS_LOG4J_LOGLEVEL: ERROR
      KAFKA_LOG_RETENTION_MS: -1
      KAFKA_LOG4J_LOGGERS: org.apache.zookeeper=WARN,org.apache.kafka=WARN,kafka=WARN,kafka.cluster=WARN,kafka.controller=WARN,kafka.coordinator=WARN,kafka.log=WARN,kafka.server=WARN,kafka.zookeeper=WARN,state.change.logger=WARN
    volumes:
      - $PWD/kafka-ce/broker/data:/var/lib/kafka/data
    restart: always

  ####################
  # schema-registry
  ####################
  schema-registry:
    image: confluentinc/cp-schema-registry:${KAFKA_VERSION}
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - zookeeper
      - broker
    networks:
      - backend
    ports:
      - ${SCHEMA_REGISTRY_PORT}:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:${BROKER_INTERNAL_PORT}'
      SCHEMA_REGISTRY_LISTENERS: http://${SCHEMA_REGISTRY_PUBLIC_HOST}:${SCHEMA_REGISTRY_PORT}
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: WARN
      SCHEMA_REGISTRY_TOOLS_LOG4J_LOGLEVEL: ERROR
    volumes:
      - $PWD/kafka-ce/schema-registry/data:/data
    restart: always

  ####################
  # connect
  ####################
  connect:
    image: confluentinc/cp-kafka-connect:${KAFKA_VERSION}
    hostname: connect
    container_name: connect
    depends_on:
      - zookeeper
      - broker
      - schema-registry
    networks:
      - backend
    ports:
      - ${CONNECT_PORT}:8083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:${BROKER_INTERNAL_PORT}
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: connect-distributed-group
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-status
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:${SCHEMA_REGISTRY_PORT}'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:${SCHEMA_REGISTRY_PORT}
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      # CLASSPATH required due to CC-2422
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-${KAFKA_VERSION}.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      CONNECT_PLUGIN_PATH: /usr/share/java,/usr/share/confluent-hub-components
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR
      CONNECT_LOG4J_ROOT_LOGLEVEL: WARN
      CONNECT_TOOLS_LOG4J_LOGLEVEL: ERROR
    command: 
      - bash 
      - -c 
      - |
        echo "Installing connector plugins"
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:${KAFKA_CONNECT_JDBC_VERSION}
        confluent-hub install --no-prompt streamthoughts/kafka-connect-file-pulse:${KAFKA_CONNECT_FILEPULSE_VERSION}
        #
        # -----------
        # Launch the Kafka Connect worker
        /etc/confluent/docker/run &
        #
        # Don't exit
        sleep infinity
    volumes:
      - $PWD/kafka-ce/connect/plugins:/usr/share/confluent-hub-components
      - $PWD/kafka-ce/connect/data:/data
    restart: always

  ####################
  # ksqldb-server
  ####################
  ksqldb-server:
    image: confluentinc/cp-ksqldb-server:${KAFKA_VERSION}
    hostname: ksqldb-server
    container_name: ksqldb-server
    depends_on:
      - zookeeper
      - broker
      - connect
    networks:
      - backend
    ports:
      - ${KSQLDB_PORT}:8088
    environment:
      KSQL_CONFIG_DIR: /etc/ksql
      KSQL_BOOTSTRAP_SERVERS: broker:${BROKER_INTERNAL_PORT}
      KSQL_HOST_NAME: ksqldb-server
      KSQL_LISTENERS: http://0.0.0.0:${KSQLDB_PORT}
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:${SCHEMA_REGISTRY_PORT}
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
      KSQL_KSQL_CONNECT_URL: http://connect:${CONNECT_PORT}
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: ${REPLICATION_FACTOR}
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: true
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: true
      KSQL_LOG4J_ROOT_LOGLEVEL: WARN
      KSQL_TOOLS_LOG4J_LOGLEVEL: ERROR
    restart: always

  ####################
  # ksqldb-cli
  ####################
  ksqldb-cli:
    image: confluentinc/cp-ksqldb-cli:${KAFKA_VERSION}
    hostname: ksqldb-cli
    container_name: ksqldb-cli
    depends_on:
      - zookeeper
      - broker
      - connect
      - ksqldb-server
    networks:
      - backend
    entrypoint: /bin/sh
    tty: true
    volumes:
      - $PWD/kafka-ce/ksqldb-cli/scripts:/data/scripts
    restart: always

  ####################
  # kafka-ui
  ####################
  kafka-ui:
    hostname: kafka-ui
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - ${KAFKA_UI_PORT}:8080
    networks:
      - backend
    depends_on:
      - zookeeper
      - broker
      - schema-registry
      - connect
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:${BROKER_INTERNAL_PORT}
      KAFKA_CLUSTERS_0_METRICS_PORT: ${KAFKA_UI_METRIC_PORT}
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:${SCHEMA_REGISTRY_PORT}
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://connect:${CONNECT_PORT}
      KAFKA_CLUSTERS_0_KSQLDBSERVER: http://ksqldb-server:${KSQLDB_PORT}
      KAFKA_CLUSTERS_0_READONLY: ${KAFKA_UI_READONLY}
      AUTH_TYPE: ${KAFKA_UI_AUTH_TYPE}
      SPRING_SECURITY_USER_NAME: ${KAFKA_UI_SPRING_SECURITY_USER_NAME}
      SPRING_SECURITY_USER_PASSWORD: ${KAFKA_UI_SPRING_SECURITY_USER_PASS}
    restart: always

  ####################
  # init-kafka
  ####################
  init-kafka:
    image: confluentinc/cp-kafka:${KAFKA_VERSION}
    container_name: init-kafka
    depends_on:
      - zookeeper
      - broker
      - schema-registry
      - connect
    networks:
      - backend
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server broker:${BROKER_INTERNAL_PORT} --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server broker:${BROKER_INTERNAL_PORT} --create --if-not-exists --topic ${KAFKA_DEFAULT_TOPIC_1} --replication-factor ${REPLICATION_FACTOR} --partitions ${REPLICATION_FACTOR}
      kafka-topics --bootstrap-server broker:${BROKER_INTERNAL_PORT} --create --if-not-exists --topic ${KAFKA_DEFAULT_TOPIC_2} --replication-factor ${REPLICATION_FACTOR} --partitions ${REPLICATION_FACTOR}
      kafka-topics --bootstrap-server broker:${BROKER_INTERNAL_PORT} --create --if-not-exists --topic ${KAFKA_DEFAULT_TOPIC_3} --replication-factor ${REPLICATION_FACTOR} --partitions ${REPLICATION_FACTOR}

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server broker:${BROKER_INTERNAL_PORT} --list
      "

################################################################################
#
# networks
# - backend
#
################################################################################
networks:
  backend:
    name: backend

